# Awareness Data Crawler Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# GitHub API Token (required)
# =============================================================================
# You need a GitHub Personal Access Token. Either type works:
#
# OPTION A: Fine-grained token (recommended)
#   1. Go to: https://github.com/settings/tokens?type=beta
#   2. Click "Generate new token"
#   3. Set expiration (e.g., 90 days)
#   4. Repository access: "Public Repositories (read-only)"
#   5. No additional permissions needed
#
# OPTION B: Classic token
#   1. Go to: https://github.com/settings/tokens
#   2. Click "Generate new token (classic)"
#   3. Select scope: public_repo
#
GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Multiple tokens for higher throughput (optional)
# Comma-separated list. Helps with Core API; Search API is per-IP limited.
# GITHUB_TOKENS=ghp_token1,ghp_token2,ghp_token3

# =============================================================================
# Paths (optional - defaults shown)
# =============================================================================

# SQLite database for crawl state
# AWARENESS_DB_PATH=./data/crawl_state.db

# Directory for cloned repositories
# WARNING: This can grow to several TB for large crawls
# AWARENESS_REPOS_PATH=./data/repos

# Directory for JSONL training data output
# AWARENESS_OUTPUT_PATH=./data/training
