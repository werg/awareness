[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "awareness"
version = "0.0.1"
description = "LLMs with Awareness: Decoupled Contextual Memory for Repository-Scale Reasoning"
readme = "README.md"
requires-python = ">=3.10"
license = {text = "MIT"}

dependencies = [
    "torch>=2.0.0",
    "transformers>=4.40.0",
    "accelerate>=1.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
]

data = [
    "httpx>=0.27",
    "aiofiles>=24.0",
    "aiosqlite>=0.20",
    "tqdm>=4.66",
    "tenacity>=8.2",
    "python-dotenv>=1.0",
]

proto1 = [
    "tqdm>=4.66",
    "wandb>=0.16.0",
]

training = [
    "bitsandbytes>=0.42.0",
    "peft>=0.12.0",
    "wandb>=0.16.0",
]

# FP8 training with TorchAO (recommended for Blackwell)
# NOTE: Requires nightly PyTorch for best performance. See docs/ACCELERATE_INTEGRATION.md
fp8 = [
    "torchao>=0.10.0",
]

# FP8 training with TransformerEngine (alternative)
fp8-te = [
    "transformer-engine[pytorch]>=1.0.0",
]

# Full Blackwell optimization (both backends available)
blackwell = [
    "bitsandbytes>=0.42.0",
    "peft>=0.12.0",
    "torchao>=0.10.0",
    "transformer-engine[pytorch]>=1.0.0",
    # torchao installed separately via nightly index
]

all = [
    "awareness[dev,data,proto1,training]",
]

[project.scripts]
awareness-data = "awareness.data.cli:main"
awareness-crawl = "awareness.data.cli:main"  # Alias for compatibility

[tool.hatch.build.targets.wheel]
packages = ["src/awareness"]

[tool.pytest.ini_options]
testpaths = ["tests"]
